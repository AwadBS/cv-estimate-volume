{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Estimate Volume of an Object\n",
    "\n",
    "This is programming project aims to estimate the volume of an object using stereo vision. The procedure is described on page 67 of the document below, as well as this write up. \n",
    "Some parts of the code is recycled from previous projects.\n",
    "\n",
    "https://carlos-hernandez.org/papers/fnt_mvs_2015.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code (run this first)\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_image(filepath):\n",
    "    \"\"\"Loads an image into a numpy array.\n",
    "    Note: image will have 3 color channels [r, g, b].\"\"\"\n",
    "    img = Image.open(filepath)\n",
    "    return (np.asarray(img).astype(np.float)/255)[:, :, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Initial Feature Matching\n",
    "We need to detect blob and corner features\n",
    "in each image using the Difference-of-Gaussian (DoG) and Harris operators. (p.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv.SIFT_create() # sift detector uses difference of gaussian for feature detection\n",
    "\n",
    "# get feature matches between two images using SIFT\n",
    "def get_point_matches(img1, img2):\n",
    "    \"\"\"Returns matches as array: (feature track, image, coord)\"\"\"\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=10)\n",
    "    search_params = dict(checks=100)\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "        \n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "    F, mask = cv.findFundamentalMat(pts1, pts2, cv.FM_LMEDS)\n",
    "    # We select only inlier points\n",
    "    pts1 = pts1[mask.ravel()==1]\n",
    "    pts2 = pts2[mask.ravel()==1]\n",
    "    \n",
    "    return np.stack((pts1, pts2), axis=1)\n",
    "# combine feature matches\n",
    "def combine_matches(matches_a, matches_b):\n",
    "    \"\"\"Assumes that the 0'th image is the same between them.\"\"\"\n",
    "    combined_matches = []\n",
    "    for ii in range(matches_a.shape[0]):\n",
    "        ma0 = matches_a[ii, 0]\n",
    "        # Find the match in b\n",
    "        mi = np.where((matches_b[:, 0] == ma0).all(axis=1))[0]\n",
    "\n",
    "        # If a match is found, add to the array\n",
    "        if mi.size > 0:\n",
    "            ma = matches_a[ii]\n",
    "            mb = matches_b[int(mi[0])]\n",
    "            combined_matches.append(np.concatenate(\n",
    "                (ma, mb[1:]), axis=0))\n",
    "\n",
    "    return np.array(combined_matches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RANSAC Solution\n",
    "\n",
    "def solve_homography_ransac(matches, rounds=100, sigma=5, s=4):\n",
    "    num_inliers = 0\n",
    "    best_inliers = []\n",
    "    best_H = []\n",
    "    \n",
    "    def get_inliers(matches, H, dist=sigma, chsq_thresh=5.99):\n",
    "        orig_points = np.ones((matches.shape[0], 3))\n",
    "        orig_points = np.stack(\n",
    "            (matches[:, 0], matches[:, 1], np.ones(matches.shape[0])),\n",
    "            axis=-1)\n",
    " \n",
    "        trans_points = np.matmul(H, orig_points.T).T\n",
    "        trans_points[:, 0] = trans_points[:, 0] / trans_points[:, 2]\n",
    "        trans_points[:, 1] = trans_points[:, 1] / trans_points[:, 2]\n",
    "        target_points = np.stack(\n",
    "            (matches[:, 2], matches[:, 3], np.ones(matches.shape[0])),\n",
    "            axis=-1)\n",
    "        rsq = (\n",
    "            np.abs(trans_points[:, 0] - target_points[:, 0]) ** 2 +\n",
    "            np.abs(trans_points[:, 1] - target_points[:, 1]) ** 2\n",
    "        )\n",
    "        return matches[rsq <= chsq_thresh * (dist**2)]\n",
    "\n",
    "    for _ in range(rounds):\n",
    "        ps = np.random.choice(np.arange(matches.shape[0]), size=s)\n",
    "        ms = matches[ps]\n",
    "        H = solve_homography(ms, img_base, img_transformed)\n",
    "        inliers = get_inliers(matches, H, sigma)\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_inliers = inliers\n",
    "            best_H = H.copy()\n",
    "\n",
    "    best_H = solve_homography(best_inliers, img_base, img_transformed)\n",
    "    best_inliers = get_inliers(matches, best_H, sigma)\n",
    "\n",
    "    return best_H\n",
    "\n",
    "\n",
    "TEST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter code (run this first)\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filepath):\n",
    "    \"\"\"Loads an image into a numpy array.\n",
    "    Note: image will have 3 color channels [r, g, b].\"\"\"\n",
    "    img = np.float32(Image.open(filepath))\n",
    "    #img = ImageOps.grayscale(img)\n",
    "    return cv.normalize(img, None, 0, 255, cv.NORM_MINMAX).astype('uint8')\n",
    "    #return (np.asarray(img).astype('uint8')/255)[:, :, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv.SIFT_create() # sift detector uses difference of gaussian for feature detection\n",
    "\n",
    "# get feature matches between two images using SIFT\n",
    "def get_point_matches(img1, img2):\n",
    "    \"\"\"Returns matches as array: (feature track, image, coord)\"\"\"\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=10)\n",
    "    search_params = dict(checks=100)\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.85*n.distance:\n",
    "            good.append(m)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "        \n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "    F, mask = cv.findFundamentalMat(pts1, pts2, cv.FM_LMEDS)\n",
    "    # We select only inlier points\n",
    "    pts1 = pts1[mask.ravel()==1]\n",
    "    pts2 = pts2[mask.ravel()==1]\n",
    "    \n",
    "    pt1 = np.append(pts1[0],1)\n",
    "    pt2 = np.append(pts2[0],1)\n",
    "    epi_cnst = np.transpose(pt2)@F@pt1\n",
    "    print(\"Epipolar constraint is \", epi_cnst)\n",
    "    \n",
    "    f = 0.05\n",
    "    K1 = [[f, 0, img1.shape[0]/2],\n",
    "     [0, f, img1.shape[1]/2],\n",
    "     [0, 0, 1]]\n",
    "    \n",
    "    K2 = [[f, 0, img1.shape[0]/2 + .00918],\n",
    "     [0, f, img1.shape[1]/2 + .00246],\n",
    "     [0, 0, 1]]\n",
    "    \n",
    "    \n",
    "    E_mat = np.transpose(K2)@F@K1\n",
    "    u, s, vh = np.linalg.svd(E_mat, full_matrices=False)\n",
    "    newE = u@np.eye(3)@np.transpose(vh)\n",
    "    u, s, vh = np.linalg.svd(newE, full_matrices=False)\n",
    "    \n",
    "    W = np.eye(3)\n",
    "    \n",
    "    R1 = u@W@np.transpose(vh)\n",
    "    R2 = u@np.transpose(W)@np.transpose(vh)\n",
    "    print(\"u is \", u)\n",
    "    \n",
    "    u = np.array(u)\n",
    "    t1 = u[:,-1]\n",
    "    t2 = -u[:,-1]\n",
    "    \n",
    "    \n",
    "    return np.stack((pts1, pts2), axis=1), pts1, pts2, F, R1, R2, t1, t2\n",
    "# combine feature matches\n",
    "def combine_matches(matches_a, matches_b):\n",
    "    \"\"\"Assumes that the 0'th image is the same between them.\"\"\"\n",
    "    combined_matches = []\n",
    "    for ii in range(matches_a.shape[0]):\n",
    "        ma0 = matches_a[ii, 0]\n",
    "        # Find the match in b\n",
    "        mi = np.where((matches_b[:, 0] == ma0).all(axis=1))[0]\n",
    "\n",
    "        # If a match is found, add to the array\n",
    "        if mi.size > 0:\n",
    "            ma = matches_a[ii]\n",
    "            mb = matches_b[int(mi[0])]\n",
    "            combined_matches.append(np.concatenate(\n",
    "                (ma, mb[1:]), axis=0))\n",
    "\n",
    "    return np.array(combined_matches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_matches(img_a, img_b, matches, ax=None):\n",
    "    #if ax is None:\n",
    "        #fig = plt.figure(figsize=(20,20))\n",
    "        #ax = plt.gca()\n",
    "    \n",
    "    sa = img_a.shape\n",
    "    sb = img_b.shape\n",
    "    sp = 40\n",
    "    off = sa[1]+sp\n",
    "    \n",
    "    merged_imgs = np.zeros(\n",
    "        (max(sa[0], sb[0]), sa[1]+sb[1]+sp),\n",
    "        dtype=np.float)\n",
    "    merged_imgs[0:sa[0], 0:sa[1]] = img_a\n",
    "    merged_imgs[0:sb[0], sa[1]+sp:] = img_b\n",
    "    #ax.imshow(merged_imgs)\n",
    "    \n",
    "    #for m in matches:\n",
    "        #ax.plot([m[0][0], m[1][0]+off], [m[0][1], m[1][1]], 'r', alpha=0.5)\n",
    "\n",
    "def get_match_colors(image_c, combined_matches):\n",
    "    colors = []\n",
    "    nm = combined_matches.shape[0]\n",
    "    for mi in range(nm):\n",
    "        m = combined_matches[mi, 0, :]\n",
    "        colors.append(image_c[m[1]-1:m[1]+2,\n",
    "                              m[0]-1:m[0]+2].sum(axis=0).sum(axis=0)/9)\n",
    "    \n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_two(test1,test2,pts1,pts2, F):\n",
    "    png = \"1.png\"\n",
    "    h1,w1 = test1.shape\n",
    "    h2,w2 = test2.shape\n",
    "    _, H1, H2 = cv.stereoRectifyUncalibrated(np.float32(pts1), np.float32(pts2), F, imgSize=(w1,h1))\n",
    "    \n",
    "    img1_rectified = cv.warpPerspective(test1, H1, (w1,h1))\n",
    "    img2_rectified = cv.warpPerspective(test2, H2, (w2,h2))\n",
    "    \n",
    "    #fig, axes = plt.subplots(1,2, figsize=(15, 10))\n",
    "    #axes[0].imshow(img1_rectified, cmap=\"gray\")\n",
    "    #axes[1].imshow(img2_rectified, cmap='gray')\n",
    "    #axes[0].axhline(400)\n",
    "    #axes[1].axhline(400)\n",
    "    #axes[0].axhline(600)\n",
    "    #axes[1].axhline(600)\n",
    "\n",
    "    \n",
    "    return img1_rectified, img2_rectified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_points(three_images_arr, i, depth_map):\n",
    "    if len(three_images_arr) != 3:\n",
    "        raise ValueError('Array must have 3 images')\n",
    "    test1 = cv.imread(three_images_arr[0],0)\n",
    "    test2 = cv.imread(three_images_arr[1],0)\n",
    "    test3 = cv.imread(three_images_arr[2],0)\n",
    "    matches1, pts1,pts2,F,R1,R2,t1,t2 = get_point_matches(test1, test2)\n",
    "    matches2, pts1_1,pts2_1,F_1,R1_1,R2_1,t1_1,t2_1 = get_point_matches(test1, test3)\n",
    "    \n",
    "    visualize_matches(test1, test2, matches1, ax=None)\n",
    "    visualize_matches(test1, test3, matches2, ax=None)\n",
    "    \n",
    "    img1_rectified, img2_rectified = rectify_two(test1,test2,pts1,pts2, F)\n",
    "    img1_rectified, img3_rectified = rectify_two(test1,test3,pts1_1,pts2_1, F_1)\n",
    "    \n",
    "    combined_matches = combine_matches(np.array(matches1), np.array(matches2)) \n",
    "    colors = get_match_colors(load_image(three_images_arr[0]), combined_matches)\n",
    "\n",
    "    return combined_matches, colors, img1_rectified, img2_rectified, img3_rectified, R1,R2,t1,t2,R1_1,R2_1,t1_1,t2_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = load_image('./world_rotate/trans_01.png')\n",
    "#fig1 = plt.figure()\n",
    "#plt.imshow(test1[:, :, 0])\n",
    "\n",
    "#fig2 = plt.figure()\n",
    "test2 = load_image('./world_rotate/trans_02.png')\n",
    "#plt.imshow(test2[:, :, 0])\n",
    "\n",
    "#fig3 = plt.figure()\n",
    "test3 = load_image('./world_rotate/trans_03.png')\n",
    "#plt.imshow(test3[:, :, 0])\n",
    "\n",
    "depth_map = cv.imread('./world_rotate/depth_map_world.png')\n",
    "depth_map = cv.cvtColor(depth_map, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "#fig1 = plt.figure()\n",
    "#plt.imshow(depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epipolar constraint is  -0.006032048915757926\n",
      "u is  [[-1.77992450e-01 -9.83968284e-01  1.11849973e-02]\n",
      " [-9.82082748e-01  1.78343474e-01  6.08858079e-02]\n",
      " [ 6.19044752e-02  1.47378715e-04  9.98082068e-01]]\n",
      "Epipolar constraint is  -0.014964823868387267\n",
      "u is  [[-9.97275062e-01 -2.98386356e-02  6.74692945e-02]\n",
      " [ 7.37729259e-02 -4.04263743e-01  9.11662427e-01]\n",
      " [ 7.26265829e-05  9.14155612e-01  4.05363433e-01]]\n"
     ]
    }
   ],
   "source": [
    "three_images =  ['./world_rotate/trans_01.png','./world_rotate/trans_02.png','./world_rotate/trans_03.png']\n",
    "X, colors, img1_rectified, img2_rectified, img3_rectified, R1,R2,t1,t2, R1_1,R2_1,t1_1,t2_1 = set_points(three_images, 0, depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[829, 357],\n",
       "        [809, 340],\n",
       "        [801, 321]],\n",
       "\n",
       "       [[869, 488],\n",
       "        [820, 472],\n",
       "        [785, 451]],\n",
       "\n",
       "       [[882, 501],\n",
       "        [831, 486],\n",
       "        [792, 465]],\n",
       "\n",
       "       [[887, 502],\n",
       "        [834, 487],\n",
       "        [794, 468]],\n",
       "\n",
       "       [[890, 442],\n",
       "        [841, 428],\n",
       "        [804, 410]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_depth_2(img1_rectified, img2_rectified):\n",
    "    stereoSGBM = cv.StereoSGBM_create(minDisparity=0, \n",
    "                                   numDisparities = 64,\n",
    "                                   blockSize = 3,\n",
    "                                   P1 = 8*1*3*3, \n",
    "                                   P2 = 32*1*3*3\n",
    "                                  )\n",
    "    dispSGBM = stereoSGBM.compute(img1_rectified, img2_rectified).astype(np.float32) / 16\n",
    "    #fig1 = plt.figure()\n",
    "    #plt.imshow(dispSGBM, 'gray')\n",
    "    #plt.colorbar()\n",
    "    \n",
    "    stereoBM = cv.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "    dispBM = stereoBM.compute(img1_rectified, img2_rectified)\n",
    "    \n",
    "    #fig2 = plt.figure()\n",
    "    #plt.imshow(dispBM, 'gray')\n",
    "    #plt.colorbar()\n",
    "dispSGBM_1 = get_depth_2(img1_rectified, img2_rectified)\n",
    "\n",
    "dispSGBM_2 = get_depth_2(img2_rectified, img3_rectified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map = cv.imread('./world_rotate/depth_map_world.png',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 16.7 GiB for an array with shape (1080, 1920, 1080) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-44955c9ec79f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mN2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mN3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#xyz = np.random.normal(0, 1, (100, 3)).astype(np.float32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 16.7 GiB for an array with shape (1080, 1920, 1080) and data type float64"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "N1 = test1.shape[0]\n",
    "N2 = test1.shape[1]\n",
    "N3 = test1.shape[0]\n",
    "ma = np.zeros((N1,N2,N3))#\n",
    "\n",
    "#xyz = np.random.normal(0, 1, (100, 3)).astype(np.float32)\n",
    "#features = np.ones_like(xyz)\n",
    "#oc_from_pcl = pyoctnet.Octree.create_from_pc(xyz, features, vx_res,vx_res,vx_res, normalize=True, n_threads=n_threads)\n",
    "\n",
    "\n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = fig.gca(projection='3d')\n",
    "#ax.set_aspect('auto')\n",
    "#ax.voxels(ma, edgecolor=\"k\")\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = [np.array(i) for i in X[:,0].tolist()]\n",
    "pb = [np.array(i) for i in X[:,1].tolist()]\n",
    "pc = [np.array(i) for i in X[:,2].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-66-de7167cd2d24>, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-66-de7167cd2d24>\"\u001b[1;36m, line \u001b[1;32m53\u001b[0m\n\u001b[1;33m    or (test1[TD_X[0],TD_X[1]] - test2[TD_Y[0],TD_Y[1]] != 0) or test1[TD_X[0],TD_X[1]] == 255):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "f = 188.9 \n",
    "\n",
    "# Camera matrix\n",
    "K = [[f, 0, img1_rectified.shape[0]/2],\n",
    "     [0, f, img1_rectified.shape[1]/2],\n",
    "     [0, 0, 1]]\n",
    "R = np.eye(3)\n",
    "ta = [[0],[0],[1]]\n",
    "Pb = K @ np.concatenate((R, ta), axis=1)\n",
    "\n",
    "def rot_trans(Pa):\n",
    "    R = [[np.cos(15),-np.sin(15),0],\n",
    "         [np.sin(15),np.cos(15),0],\n",
    "         [0,0,1]]     \n",
    "    tb = [[34.720032502], [9.3071030883], [0]] \n",
    "    Pb = Pa @ np.concatenate((R, tb), axis=1)\n",
    "    return Pb\n",
    "\n",
    "def get_projected_point(P, X):\n",
    "    Xh = np.concatenate((X, [1]), axis=0)\n",
    "    PX_inh = P @ Xh\n",
    "    PX = PX_inh[:2]/PX_inh[2]\n",
    "    return PX\n",
    "\n",
    "X0 = np.array([ 0.85244616, 0.9508618, -0.51819406])\n",
    "points_3D = [X0]\n",
    "\n",
    "\n",
    "i_coords, j_coords, k_coords = np.meshgrid(range(N1), range(N2), range(N3), indexing='ij')\n",
    "coordinate_grid = np.array([i_coords, j_coords,k_coords])\n",
    "\n",
    "print(coordinate_grid[:, 0, 0, 0])\n",
    "\n",
    "import os\n",
    "\n",
    "filelist = os.listdir('./world_rotate/')\n",
    "filelist = sorted(filelist,key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "for i in range(len(filelist)-1):\n",
    "    test1 = filelist[i]\n",
    "    test2 = filelist[i+1]\n",
    "    Pa = Pb\n",
    "    Pb = rot_trans(Pa)\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            for k in range(N3):\n",
    "                pt = coordinate_grid[:, i, j, k]\n",
    "                TD_X = get_projected_point(Pa,pt)\n",
    "                TD_Y = get_projected_point(Pb,pt)\n",
    "                #need to come up with a better metric\n",
    "                #and perhaps down \n",
    "                if((TD_X[0] < test1.shape[0] and TD_Y[0] < test1.shape[0]) and (TD_X[1] < test1.shape[1] and TD_Y1[1] < test.shape[1]) or\n",
    "                   and (test1[TD_X[0],TD_X[1]] - test2[TD_Y[0],TD_Y[1]] == 0) and test1[TD_X[0],TD_X[1]] != 255):\n",
    "                    ma[i,j,k] = 1\n",
    "\n",
    "\n",
    "def visualize_projected_points(image, P, points_3D, verbose=False):\n",
    "    plt.figure(dpi=100)\n",
    "    plt.imshow(image)\n",
    "    for X in points_3D:\n",
    "        x = get_projected_point(P, X)\n",
    "        if verbose:\n",
    "            print(x)\n",
    "        plt.plot(x[0], x[1], 'ko')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.set_aspect('auto')\n",
    "ax.voxels(ma, edgecolor=\"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.75968791  0.65028784  0.        ]\n",
      " [-0.65028784 -0.75968791  0.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "[[-20.32409306]\n",
      " [-29.64850867]\n",
      " [  0.        ]]\n",
      "[[ -0.75968791   0.65028784   0.         -20.32409306]\n",
      " [ -0.65028784  -0.75968791   0.         -29.64850867]\n",
      " [  0.           0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K = [[f, 0, img1_rectified.shape[0]/2, 0],\n",
    " [0, f, img1_rectified.shape[1]/2, 0],\n",
    " [0, 0, 1, 0]]\n",
    "\n",
    "R_inv = np.asmatrix([[np.cos(15),np.sin(15),0],\n",
    "     [-np.sin(15),np.cos(15),0],\n",
    "     [0,0,0]])  \n",
    "\n",
    "tb = np.asmatrix([[34.720032502], [9.3071030883], [1]])\n",
    "\n",
    "R_inv_t = R_inv @ tb\n",
    "RRT = np.concatenate((R_inv, R_inv_t), axis=1)\n",
    "\n",
    "\n",
    "p_11 = RRT[0,0]\n",
    "p_12 = RRT[0,1]\n",
    "p_13 = RRT[0,2]\n",
    "p_14 = RRT[0,3]\n",
    "\n",
    "p_21 = RRT[1,0]\n",
    "p_22 = RRT[1,1]\n",
    "p_23 = RRT[1,2]\n",
    "p_24 = RRT[1,3]\n",
    "\n",
    "p_31 = RRT[2,0]\n",
    "p_32 = RRT[2,1]\n",
    "p_33 = RRT[2,2]\n",
    "p_34 = RRT[2,3]\n",
    "\n",
    "\n",
    "def plane_1(pt):\n",
    "    X, Y, Z = pt[:]\n",
    "    \n",
    "X*(p_11 - u*p_31) + Y*(p_12 - u*P_32) + Z*(p_13 - u*p_33) + p_14 - u*p_34 = 0\n",
    "#X*(p_21 - v*p_31) + Y*(p_22 - v*P_32) + Z*(p_23 - v*p_33) + p_24 - v*p_34 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-64b3d2a682ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bpy'"
     ]
    }
   ],
   "source": [
    "import bpy\n",
    "import numpy as np\n",
    "\n",
    "import bpy\n",
    "\n",
    "filepath = \"C:/Users/Helena Gray/Downloads/world_files/WorldBlender.blend\"\n",
    "\n",
    "# load a single scene we know the name of.\n",
    "with bpy.data.libraries.load(filepath) as (data_from, data_to):\n",
    "    data_to.scenes = [\"Scene\"]\n",
    "    \n",
    "    \n",
    "def get_calibration_matrix_K_from_blender(mode='simple'):\n",
    "\n",
    "    scene = bpy.context.scene\n",
    "\n",
    "    scale = scene.render.resolution_percentage / 100\n",
    "    width = scene.render.resolution_x * scale # px\n",
    "    height = scene.render.resolution_y * scale # px\n",
    "\n",
    "    camdata = scene.camera.data\n",
    "\n",
    "    if mode == 'simple':\n",
    "\n",
    "        aspect_ratio = width / height\n",
    "        K = np.zeros((3,3), dtype=np.float32)\n",
    "        K[0][0] = width / 2 / np.tan(camdata.angle / 2)\n",
    "        K[1][1] = height / 2. / np.tan(camdata.angle / 2) * aspect_ratio\n",
    "        K[0][2] = width / 2.\n",
    "        K[1][2] = height / 2.\n",
    "        K[2][2] = 1.\n",
    "        K.transpose()\n",
    "    \n",
    "    if mode == 'complete':\n",
    "\n",
    "        focal = camdata.lens # mm\n",
    "        sensor_width = camdata.sensor_width # mm\n",
    "        sensor_height = camdata.sensor_height # mm\n",
    "        pixel_aspect_ratio = scene.render.pixel_aspect_x / scene.render.pixel_aspect_y\n",
    "\n",
    "        if (camdata.sensor_fit == 'VERTICAL'):\n",
    "            # the sensor height is fixed (sensor fit is horizontal), \n",
    "            # the sensor width is effectively changed with the pixel aspect ratio\n",
    "            s_u = width / sensor_width / pixel_aspect_ratio \n",
    "            s_v = height / sensor_height\n",
    "        else: # 'HORIZONTAL' and 'AUTO'\n",
    "            # the sensor width is fixed (sensor fit is horizontal), \n",
    "            # the sensor height is effectively changed with the pixel aspect ratio\n",
    "            pixel_aspect_ratio = scene.render.pixel_aspect_x / scene.render.pixel_aspect_y\n",
    "            s_u = width / sensor_width\n",
    "            s_v = height * pixel_aspect_ratio / sensor_height\n",
    "\n",
    "        # parameters of intrinsic calibration matrix K\n",
    "        alpha_u = focal * s_u\n",
    "        alpha_v = focal * s_v\n",
    "        u_0 = width / 2\n",
    "        v_0 = height / 2\n",
    "        skew = 0 # only use rectangular pixels\n",
    "\n",
    "        K = np.array([\n",
    "            [alpha_u,    skew, u_0],\n",
    "            [      0, alpha_v, v_0],\n",
    "            [      0,       0,   1]\n",
    "        ], dtype=np.float32)\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
